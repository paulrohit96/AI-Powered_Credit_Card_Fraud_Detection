{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdLTlem-NU5b",
        "outputId": "1fcb886a-0068-4936-e02a-f011902886f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 3945.7920 - val_loss: 3953.9412\n",
            "Epoch 2/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 3943.5535 - val_loss: 3953.9414\n",
            "Epoch 3/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 3943.8987 - val_loss: 3953.9407\n",
            "Epoch 4/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3947.6506 - val_loss: 3953.9407\n",
            "Epoch 5/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3943.8638 - val_loss: 3953.9407\n",
            "Epoch 6/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3945.1687 - val_loss: 3953.9407\n",
            "Epoch 7/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3945.0833 - val_loss: 3953.9407\n",
            "Epoch 8/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3941.0662 - val_loss: 3953.9407\n",
            "Epoch 9/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3941.3372 - val_loss: 3953.9407\n",
            "Epoch 10/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3946.5234 - val_loss: 3953.9407\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "Processing Rows:  63%|██████▎   | 6304/10000 [24:58<13:38,  4.51it/s]/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "Processing Rows: 100%|██████████| 10000/10000 [39:16<00:00,  4.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Fraud cases detected and saved to fraud_cases_with_reasons.csv (10000 cases)\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_45506ffd-d6ba-4f37-9eac-1dc7c729ba60\", \"fraud_cases_with_reasons.csv\", 42116633)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📥 File ready for download!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/realistic_credit_card_transactions (1).csv\")\n",
        "\n",
        "\n",
        "df[\"Transaction_Date\"] = pd.to_datetime(df[\"Transaction_Date\"])\n",
        "\n",
        "\n",
        "df[\"Transaction_Hour\"] = df[\"Transaction_Date\"].dt.hour\n",
        "df[\"Transaction_Day\"] = df[\"Transaction_Date\"].dt.dayofweek\n",
        "df[\"Transaction_Month\"] = df[\"Transaction_Date\"].dt.month\n",
        "\n",
        "\n",
        "df[\"Merchant_Name\"] = df[\"Merchant_Name\"].astype(\"category\").cat.codes\n",
        "\n",
        "df[\"Transaction_Amount\"] = StandardScaler().fit_transform(df[\"Transaction_Amount\"].values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "df[\"Transaction_Frequency\"] = df.groupby(\"Customer_ID\")[\"Transaction_ID\"].transform(\"count\")\n",
        "df[\"Location_Mismatch\"] = df.groupby(\"Customer_ID\")[\"Transaction_Location\"].transform(lambda x: x != x.mode()[0])\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
        "encoded_categories = encoder.fit_transform(df[[\"Merchant_Category\", \"Transaction_Location\"]])\n",
        "encoded_categories_df = pd.DataFrame(encoded_categories, columns=encoder.get_feature_names_out([\"Merchant_Category\", \"Transaction_Location\"]))\n",
        "df = pd.concat([df, encoded_categories_df], axis=1)\n",
        "\n",
        "\n",
        "X = df.drop(columns=[\"Fraud_Flag\", \"Transaction_Date\", \"Transaction_ID\", \"Customer_ID\", \"Merchant_Name\", \"Merchant_Category\", \"Transaction_Location\"])\n",
        "y = df[\"Fraud_Flag\"]\n",
        "\n",
        "\n",
        "X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "iso_forest = IsolationForest(contamination=0.01, random_state=42)\n",
        "iso_forest.fit(X_train)\n",
        "\n",
        "\n",
        "oc_svm = OneClassSVM(nu=0.01, kernel=\"rbf\", gamma=\"auto\")\n",
        "oc_svm.fit(X_train)\n",
        "\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "autoencoder = Sequential([\n",
        "    Dense(16, activation=\"relu\", input_shape=(input_dim,)),\n",
        "    Dense(8, activation=\"relu\"),\n",
        "    Dense(16, activation=\"relu\"),\n",
        "    Dense(input_dim, activation=\"sigmoid\")\n",
        "])\n",
        "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "autoencoder.fit(X_train, X_train, epochs=10, batch_size=32, shuffle=True, validation_data=(X_test, X_test), verbose=1)\n",
        "\n",
        "joblib.dump(iso_forest, \"isolation_forest.pkl\")\n",
        "joblib.dump(oc_svm, \"one_class_svm.pkl\")\n",
        "autoencoder.save(\"autoencoder_model.h5\")\n",
        "\n",
        "\n",
        "def detect_fraud_with_reason(transaction):\n",
        "    \"\"\"Detects fraud using trained models and returns real-world reasons and model reasons.\"\"\"\n",
        "    transaction = np.array(transaction).reshape(1, -1)\n",
        "\n",
        "\n",
        "    iso_forest = joblib.load(\"isolation_forest.pkl\")\n",
        "    oc_svm = joblib.load(\"one_class_svm.pkl\")\n",
        "    autoencoder = load_model(\"autoencoder_model.h5\", custom_objects={\"mse\": MeanSquaredError()})\n",
        "\n",
        "\n",
        "    iso_pred = iso_forest.predict(transaction)[0]  # -1 for fraud\n",
        "    svm_pred = oc_svm.predict(transaction)[0]  # -1 for fraud\n",
        "    auto_pred = np.mean((autoencoder.predict(transaction) - transaction) ** 2)  # MSE threshold\n",
        "\n",
        "    # real-world reasons for fraud\n",
        "    real_world_reasons = []\n",
        "    if transaction[0][3] > 3:  # Unusual Transaction Amount (scaled amount > 3)\n",
        "        real_world_reasons.append(\"Unusual Transaction Amount\")\n",
        "    if transaction[0][6] == 1:  # Location Mismatch (1 = mismatch)\n",
        "        real_world_reasons.append(\"Geographic Anomaly\")\n",
        "    if transaction[0][7] > 5:  # High-Frequency Transactions (more than 5 in a short time)\n",
        "        real_world_reasons.append(\"High-Frequency Transactions\")\n",
        "    if transaction[0][4] == \"Unusual Merchant\":  # Unusual Merchant Category\n",
        "        real_world_reasons.append(\"Unusual Merchant Category\")\n",
        "    if transaction[0][2] < 6 or transaction[0][2] > 22:  # Unusual Time of Day (late night/early morning)\n",
        "        real_world_reasons.append(\"Unusual Time of Day\")\n",
        "\n",
        "    # model reasons for fraud\n",
        "    model_reasons = []\n",
        "    if iso_pred == -1:\n",
        "        model_reasons.append(\"Isolation Forest flagged as anomaly\")\n",
        "    if svm_pred == -1:\n",
        "        model_reasons.append(\"One-Class SVM flagged as anomaly\")\n",
        "    if auto_pred > 0.01:\n",
        "        model_reasons.append(\"Autoencoder detected high reconstruction error\")\n",
        "\n",
        "    # If at least two models flag it as fraud, mark it as fraudulent\n",
        "    if (iso_pred == -1 and svm_pred == -1) or auto_pred > 0.01:\n",
        "        return [1, \", \".join(real_world_reasons), \", \".join(model_reasons)]  # Fraud with reasons\n",
        "    else:\n",
        "        return [0, \"\", \"\"]  # Legitimate\n",
        "\n",
        "\n",
        "def process_row(row):\n",
        "    \"\"\"Process a single row for fraud detection.\"\"\"\n",
        "    row_numeric = row.astype(float)  # Convert to numeric\n",
        "    return detect_fraud_with_reason(row_numeric)\n",
        "\n",
        "\n",
        "results = Parallel(n_jobs=-1)(delayed(process_row)(row) for _, row in tqdm(X.iterrows(), total=len(X), desc=\"Processing Rows\"))\n",
        "\n",
        "\n",
        "fraud_predictions = [result[0] for result in results]\n",
        "real_world_reasons = [result[1] for result in results]\n",
        "model_reasons = [result[2] for result in results]\n",
        "\n",
        "# Step 13: Add Results to the DataFrame\n",
        "df[\"Fraud_Prediction\"] = fraud_predictions\n",
        "df[\"Real_World_Reason\"] = real_world_reasons\n",
        "df[\"Model_Reason\"] = model_reasons\n",
        "\n",
        "#save cases\n",
        "fraud_cases = df[df[\"Fraud_Prediction\"] == 1]\n",
        "fraud_cases.to_csv(\"fraud_cases_with_reasons.csv\", index=False)\n",
        "\n",
        "print(f\"Fraud cases detected and saved to fraud_cases_with_reasons.csv ({len(fraud_cases)} cases)\")\n",
        "\n",
        "\n",
        "#download saved cases file\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"fraud_cases_with_reasons.csv\")\n",
        "    print(\" File ready for download!\")\n",
        "except:\n",
        "    print(\" Run this in Colab for auto-download, or check fraud_cases_with_reasons.csv in your directory.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}